{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuroTac Spiking Neural Network Demo\n",
    "\n",
    "Intro paragraph or something here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data collection\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.data_gatherer_neurotac import DataCollector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can collect data from the neuroTac in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection code\n",
    "sensor_type = 'DAVIS240C_84010012'\n",
    "path = \"/home/farscope2/Documents/PhD/Lava_Demo/tests/\"\n",
    "collector = DataCollector(sensor_type)\n",
    "data_path = collector.main(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/farscope2/Documents/PhD/Lava_Demo/tests/DAVIS240C_84010012/data_gatherer_neurotac_11061641/events/taps_object_0_trial_0_events_on\n"
     ]
    }
   ],
   "source": [
    "print(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting the data, within this particular demo, the data must be preprocessed before being passed into our pretrained spiking neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_processor import DataProcessor\n",
    "\n",
    "sample_length = 3000\n",
    "data = DataProcessor.load_data_np(f\"{data_path}.npy\")\n",
    "\n",
    "if sensor_type == \"DAVIS240C_84010012\":\n",
    "    data.pixel_reduction(40, 30, 20, 0)  # Crop data\n",
    "else:\n",
    "    data.pixel_reduction(160, 170, 60, 110)\n",
    "data.remove_cuttoff(sample_length)\n",
    "data.remove_duplicates()\n",
    "data.threshold_pooling((4, 4), 4, 1)\n",
    "input_tensor = data.create_lava_array(sample_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will create our lava process components that are required to feed data into the network and visualise the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the components of our network\n",
    "from components.visualiser import Visualiser\n",
    "# from utils.utils import calculate_pooling_dim\n",
    "\n",
    "# Import lava related libraries\n",
    "# import numpy as np\n",
    "from lava.magma.core.run_configs import Loihi2SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.proc import io\n",
    "from lava.lib.dl import netx#, slayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import trained network model\n",
    "net = netx.hdf5.Network(net_config=\"../networks/network.net\")\n",
    "# Create input ring buffer containing our input tensor we collected and preprocessed\n",
    "source = io.source.RingBuffer(data=input_tensor)\n",
    "# Output ring buffer to contain output spikes\n",
    "sink = io.sink.RingBuffer(shape=(2,), buffer=sample_length)\n",
    "# Create a visualiser object that will let us see network output in real-time\n",
    "vis = Visualiser(in_shape=net.out.shape, sample_length=sample_length, window_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect processes\n",
    "source.s_out.connect(net.inp)\n",
    "net.out.connect(sink.a_in)\n",
    "net.out.connect(vis.a_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the network for long enough to get all of the data through the network\n",
    "run_condition = RunSteps(num_steps=sample_length)\n",
    "\n",
    "# Map the defined encoder and adapter to their proc models\n",
    "run_config = Loihi2SimCfg(select_tag='fixed_pt', select_sub_proc_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the network and view the moving window of output spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run network\n",
    "print(\"Running network\")\n",
    "\n",
    "source.run(condition=run_condition, run_cfg=run_config)\n",
    "# Stop network execution\n",
    "source.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lava0.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
