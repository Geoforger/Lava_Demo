{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuroTac Spiking Neural Network Demo\n",
    "\n",
    "Intro paragraph or something here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data collection\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.data_gatherer_neurotac import DataCollector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can collect data from the neuroTac in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection code\n",
    "# sensor_type = 'DAVIS240C_84010012'\n",
    "sensor_type = \"NeuroTac_DVXplorer\"\n",
    "path = \"C:\\\\Users\\\\Ben\\OneDrive - University of Bristol\\\\repos\\\\Lava_Demo\\\\tests\"\n",
    "collector = DataCollector(sensor_type)\n",
    "data_path = collector.main(path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting the data, within this particular demo, the data must be preprocessed before being passed into our pretrained spiking neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.7'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Ben\\\\OneDrive - University of Bristol\\\\repos\\\\Lava_Demo\\\\tests\\\\NeuroTac_DVXplorer\\\\data_gatherer_neurotac_11081633\\\\events\\\\taps_object_0_trial_1_events_on.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ben\\OneDrive - University of Bristol\\repos\\Lava_Demo\\src\\LinearDemo.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ben/OneDrive%20-%20University%20of%20Bristol/repos/Lava_Demo/src/LinearDemo.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_processor\u001b[39;00m \u001b[39mimport\u001b[39;00m DataProcessor\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ben/OneDrive%20-%20University%20of%20Bristol/repos/Lava_Demo/src/LinearDemo.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sample_length \u001b[39m=\u001b[39m \u001b[39m3000\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ben/OneDrive%20-%20University%20of%20Bristol/repos/Lava_Demo/src/LinearDemo.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m data \u001b[39m=\u001b[39m DataProcessor\u001b[39m.\u001b[39;49mload_data_np(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mdata_path\u001b[39m}\u001b[39;49;00m\u001b[39m.npy\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ben/OneDrive%20-%20University%20of%20Bristol/repos/Lava_Demo/src/LinearDemo.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mif\u001b[39;00m sensor_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDAVIS240C_84010012\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ben/OneDrive%20-%20University%20of%20Bristol/repos/Lava_Demo/src/LinearDemo.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     data\u001b[39m.\u001b[39mpixel_reduction(\u001b[39m40\u001b[39m, \u001b[39m30\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m0\u001b[39m)  \u001b[39m# Crop data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ben\\OneDrive - University of Bristol\\repos\\Lava_Demo\\src\\..\\utils\\data_processor.py:65\u001b[0m, in \u001b[0;36mDataProcessor.load_data_np\u001b[1;34m(cls, path, AER)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data_np\u001b[39m(\u001b[39mcls\u001b[39m, path: \u001b[39mstr\u001b[39m, AER: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Class method to load data in from a file\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[39m    path (string): Path string to the location of data if load_data = True\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(path, allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(data, AER\u001b[39m=\u001b[39mAER)\n",
      "File \u001b[1;32mc:\\Users\\bw14452\\AppData\\Local\\Continuum\\anaconda3\\envs\\lava\\lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Ben\\\\OneDrive - University of Bristol\\\\repos\\\\Lava_Demo\\\\tests\\\\NeuroTac_DVXplorer\\\\data_gatherer_neurotac_11081633\\\\events\\\\taps_object_0_trial_1_events_on.npy'"
     ]
    }
   ],
   "source": [
    "from utils.data_processor import DataProcessor\n",
    "\n",
    "sample_length = 3000\n",
    "data = DataProcessor.load_data_np(f\"{data_path}.npy\")\n",
    "\n",
    "if sensor_type == \"DAVIS240C_84010012\":\n",
    "    data.pixel_reduction(40, 30, 20, 0)  # Crop data\n",
    "else:\n",
    "    data.pixel_reduction(184, 194, 120, 110)\n",
    "data.remove_cuttoff(sample_length)\n",
    "data.remove_duplicates()\n",
    "data.threshold_pooling((4, 4), 4, 1)\n",
    "input_tensor = data.create_lava_array(sample_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will create our lava process components that are required to feed data into the network and visualise the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the components of our network\n",
    "from components.visualiser import Visualiser\n",
    "# from utils.utils import calculate_pooling_dim\n",
    "\n",
    "# Import lava related libraries\n",
    "# import numpy as np\n",
    "from lava.magma.core.run_configs import Loihi2SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.proc import io\n",
    "from lava.lib.dl import netx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import trained network model\n",
    "if sensor_type == \"DAVIS240C_84010012\":\n",
    "    net = netx.hdf5.Network(net_config=\"../networks/davis_network.net\")\n",
    "else:\n",
    "    net = netx.hdf5.Network(net_config=\"../networks/demo_network/explorer_network.net\")\n",
    "\n",
    "# Create input ring buffer containing our input tensor we collected and preprocessed\n",
    "source = io.source.RingBuffer(data=input_tensor)\n",
    "# Output ring buffer to contain output spikes\n",
    "sink = io.sink.RingBuffer(shape=(2,), buffer=sample_length)\n",
    "# Create a visualiser object that will let us see network output in real-time\n",
    "vis = Visualiser(in_shape=net.out.shape, sample_length=sample_length, window_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect processes\n",
    "source.s_out.connect(net.inp)\n",
    "net.out.connect(sink.a_in)\n",
    "net.out.connect(vis.a_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the network for long enough to get all of the data through the network\n",
    "run_condition = RunSteps(num_steps=sample_length)\n",
    "\n",
    "# Map the defined encoder and adapter to their proc models\n",
    "run_config = Loihi2SimCfg(select_tag='fixed_pt', select_sub_proc_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the network and view the moving window of output spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running network\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'source' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ben\\OneDrive - University of Bristol\\repos\\Lava_Demo\\src\\LinearDemo.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ben/OneDrive%20-%20University%20of%20Bristol/repos/Lava_Demo/src/LinearDemo.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Run network\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ben/OneDrive%20-%20University%20of%20Bristol/repos/Lava_Demo/src/LinearDemo.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRunning network\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ben/OneDrive%20-%20University%20of%20Bristol/repos/Lava_Demo/src/LinearDemo.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m source\u001b[39m.\u001b[39mrun(condition\u001b[39m=\u001b[39mrun_condition, run_cfg\u001b[39m=\u001b[39mrun_config)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ben/OneDrive%20-%20University%20of%20Bristol/repos/Lava_Demo/src/LinearDemo.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Stop network execution\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ben/OneDrive%20-%20University%20of%20Bristol/repos/Lava_Demo/src/LinearDemo.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m source\u001b[39m.\u001b[39mstop()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'source' is not defined"
     ]
    }
   ],
   "source": [
    "# Run network\n",
    "print(\"Running network\")\n",
    "\n",
    "source.run(condition=run_condition, run_cfg=run_config)\n",
    "# Stop network execution\n",
    "source.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lava0.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
